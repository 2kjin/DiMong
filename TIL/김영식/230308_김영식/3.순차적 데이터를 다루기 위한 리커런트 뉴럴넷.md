# 순차적 데이터를 다루기 위한 리커런트 뉴럴넷

#### Artificial Intelligence Basic

- Recap - AI system<img src="3.순차적%20데이터를%20다루기%20위한%20리커런트%20뉴럴넷_assets/2023-02-23-14-43-16-image.png" title="" alt="" width="506">
  
  - 인공지능 시스템은 입력이 있을 때 그에 대한 특징을 추출하고 분류하여 적절한 출력을 보여주는 것

- Recap - Basic model
  
  <img src="3.순차적%20데이터를%20다루기%20위한%20리커런트%20뉴럴넷_assets/2023-02-23-14-56-44-image.png" title="" alt="" width="232">
  
  - W와 b는 학습 가능한 파라미터

- Recap - 학습
  
  <img src="3.순차적%20데이터를%20다루기%20위한%20리커런트%20뉴럴넷_assets/2023-02-23-15-01-39-image.png" title="" alt="" width="520">
  
  - 경험사례
    
    - data
  
  - 모델
    
    - 인공신경망
  
  - 평가기준
    
    - 인공신경망을 학습시킬 기준
  
  - 지도 학습(supervised learning) - annotation을 통한 학습
    
    <img src="3.순차적%20데이터를%20다루기%20위한%20리커런트%20뉴럴넷_assets/2023-02-23-15-05-37-image.png" title="" alt="" width="409">
    
    - annotiona이라는 label을 주고  f(data)의 출력값이 최대한 따라갈 수 있도록 학습 시키는 방법
  
  - parameter 학습(최적화)
    
    - 경사하강법(gradient descent method)
      
      <img src="3.순차적%20데이터를%20다루기%20위한%20리커런트%20뉴럴넷_assets/2023-02-23-15-08-33-image.png" title="" alt="" width="277">
      
      - 현재 학습 파라미터에서 error를 줄여나가는 방법으로 parameter 최적화

---

#### 시각적 지각 능력

<img src="3.순차적%20데이터를%20다루기%20위한%20리커런트%20뉴럴넷_assets/2023-02-23-15-10-50-image.png" title="" alt="" width="519">

- 시각은 지각 능력 중 가장 큰 부분을 담당하므로 인공지능이 시각지각 기반으로 발전
  
  - 인간은 세상을 어떻게 인식하는가
    
    <img src="3.순차적%20데이터를%20다루기%20위한%20리커런트%20뉴럴넷_assets/2023-02-23-15-17-39-image.png" title="" alt="" width="479">
  
  - 컴퓨터는 세상을 어떻게 인식하는가
    
    <img title="" src="3.순차적%20데이터를%20다루기%20위한%20리커런트%20뉴럴넷_assets/2023-02-23-15-19-54-image.png" alt="" width="489">

- 뉴럴넷의 부활
  
  - AlexNet
    
    - Deep Convolution Neural Networks
      
      - 기존에 비해 압도적인 성능차 
      
      - 2015년 이후로 사람의 인식능력을 뛰어넘음

- Convolution Neural Networks(CNN)
  
  - LeNet-5
    
    - 첫번째 컨볼루션 기반 뉴럴넷 (Yann LeCun)
    
    - 우편번호 인식에 큰 성공
      
      <img src="3.순차적%20데이터를%20다루기%20위한%20리커런트%20뉴럴넷_assets/2023-02-23-15-52-11-image.png" title="" alt="" width="320">
      
      - 우편인식을 제외하고 다른 곳에서는 인식 능력이 떨어짐

- AlexNet과 LeNet-5의 차이
  
  - layer를 쌓았을 때 아래 layer로 이동 할 수록 경사하강법의 경사도가 희석되어 제대로 적용되지 않는 문제
    
    - 알고리즘의 발전으로 문제가 해결
  
  - data set의 양의 차이
    
    - 인터넷이 발전하면서 학습시킬 수 있는 data set의 양이 증가하며 비약적으로 발전
  
  - open source 문화
    
    - 좋은 개발 결과를 공개하는 문화가 자리잡아 여러가지 좋은 코드의 조합으로 더 좋은 ai 개발 가능

---

#### CNN(Convolution Neural Networks)이란 무엇인가?

<img src="3.순차적%20데이터를%20다루기%20위한%20리커런트%20뉴럴넷_assets/2023-02-23-16-08-08-image.png" title="" alt="" width="507">

- CNN과 Fully conneted NN의 비교
  
  - convolution 뉴런은 perceptron의 일반화 된 형태
    
    - local 연산을 학습
    
    - parameter 공유
    
    <img src="3.순차적%20데이터를%20다루기%20위한%20리커런트%20뉴럴넷_assets/2023-02-23-16-11-49-image.png" title="" alt="" width="489">
    
    ---
    
    - Fully conneted NN
      
      - data에서 모든 정보를 이용
        
        - parameter가 기하급수로 증가하고 조금만 움직여도 data 값이 전부 변하게 된다
    
    - Locally conneted NN
      
      - data에서 국소적인 부분의 정보만 이용
        
        - parameter를 줄이고 다른 부분에서도 재활용할 수 있어 효율적이게 되어 더 많은 데이터를 볼 수 있다(영상에 최적화)
    
    ---
    
    - Fully conneted layer
      
      <img src="3.순차적%20데이터를%20다루기%20위한%20리커런트%20뉴럴넷_assets/2023-02-23-16-17-31-image.png" title="" alt="" width="396">
      
      - 이미지를 벡터화한 값과 W를 연산을 한 후 b를 더해 결과값을 도출
      
      - Fully conneted layer 학습 후 내적하여 유사도를 측정
        
        <img src="3.순차적%20데이터를%20다루기%20위한%20리커런트%20뉴럴넷_assets/2023-02-23-16-21-21-image.png" title="" alt="" width="371">
        
        - 사진이 잘못 짤려 입력된다면 예측 오류가 날 수 있음
  
  ---
  
  - CNN의 keywords
    
    - CNN의 구성 layers
      
      <img src="3.순차적%20데이터를%20다루기%20위한%20리커런트%20뉴럴넷_assets/2023-02-23-16-25-25-image.png" title="" alt="" width="255">
      
      - convolution layer
        
        - convolution이란?
          
          - input을 filter(W) 크기에 맞춰 잘라 두 값의 곱의 합(내적)을 output의 해당 위치에 대입
          
          ![](3.순차적%20데이터를%20다루기%20위한%20리커런트%20뉴럴넷_assets/2023-02-23-16-27-44-image.png)
          
          - 이웃한 픽셀간의 미분의 근사값으로 x값의 변화량을 추출
        
        - convolution layer
          
          <img title="" src="3.순차적%20데이터를%20다루기%20위한%20리커런트%20뉴럴넷_assets/2023-02-23-16-30-19-image.png" alt="" width="126">depth == channel (image의 경우 RGB 3색)
          
          <img src="3.순차적%20데이터를%20다루기%20위한%20리커런트%20뉴럴넷_assets/2023-02-23-17-43-31-image.png" title="" alt="" width="416">
          
          - filter 사용시 depth는 입력의 channel 축(image의 경우 RGB 3색)과 맞춰준다
          
          - 출력은 filter가 몇개가 사용됐는지에 따라 결정된다
          
          <img src="3.순차적%20데이터를%20다루기%20위한%20리커런트%20뉴럴넷_assets/2023-02-23-17-47-47-image.png" title="" alt="" width="440">
          
          - Filter로 image를 훑으면서 내적을 계산
          
          - convolution layer는 필터를 뒤집어서 연산하는 것이 엄밀한 정의
            
            - 뉴럴네트워크에서는 filter가 학습되어 뒤집는 것과 뒤집지 않은 것 모두 같은 결과 도출 가능
          
          ---
          
          - stride에 따른 filtering
          
          <img src="3.순차적%20데이터를%20다루기%20위한%20리커런트%20뉴럴넷_assets/2023-03-08-13-19-53-image.png" title="" alt="" width="319">
          
          - 7 X 7 이미지 입력시 3 X 3 filter로  필터링을해서 stride =1로 적용하면 5 X 5 결과 도출
          
          <img src="3.순차적%20데이터를%20다루기%20위한%20리커런트%20뉴럴넷_assets/2023-03-08-13-22-34-image.png" title="" alt="" width="306">
          
          - 7 X 7 이미지 입력시 3 X 3 filter로 필터링을해서 stride =2로 적용하면 3 X 3 결과 도출
          
          <img src="3.순차적%20데이터를%20다루기%20위한%20리커런트%20뉴럴넷_assets/2023-03-08-13-23-28-image.png" title="" alt="" width="157">
          
          - 7 X 7 이미지 입력시 3 X 3 filter로 필터링을해서 stride =3로 적용하면 끝에 남는 부분이 있어 처리하지 못함
          
          - => 출력사이즈 예측 : (N-F) / stride + 1
            
            <img src="3.순차적%20데이터를%20다루기%20위한%20리커런트%20뉴럴넷_assets/2023-03-08-13-25-33-image.png" title="" alt="" width="183">
            
            - 소수점이 나오는 결과가 나온다면 filtering 하지 못하는 부분이 생김
            
            - 해결방법 : zero padding
              
              <img src="3.순차적%20데이터를%20다루기%20위한%20리커런트%20뉴럴넷_assets/2023-03-08-13-28-14-image.png" title="" alt="" width="359">
              
              - 일반적으로 CONV layer를 볼 때 stride = 1, Filter의 size가 F X F, zero-padding을 (F-1)/2로 하면 filter를 거친 후에도 크기가 보존 됨
          
          - filter 결과
            
            <img src="3.순차적%20데이터를%20다루기%20위한%20리커런트%20뉴럴넷_assets/2023-03-08-13-32-33-image.png" title="" alt="" width="325">
          
          <img src="3.순차적%20데이터를%20다루기%20위한%20리커런트%20뉴럴넷_assets/2023-03-08-13-34-26-image.png" title="" alt="" width="302">
          
          - 하나의 필터가 하나의 채널을 생성
            
            - 6개의 필터를 적용하면 6개의 채널이 생성된다
          
          - convolution layer 장점
            
            - filter가 이동하며 적용 되기 때문에 영상과 같은 이동하는 이미지에 강함
          
          - convolution layer 단점
            
            - 확대나 축소된 이미지에 대한 결과 도출이 어려움
      
      ---
      
      - Pooling layer
        
        - 이미지에서 눈이 있는지 여부만을 여러 상황에서 강인하게 찾을 수 있는 방법
          
          - filter가 눈을 찾는 역할을 할 때
            
            <img src="3.순차적%20데이터를%20다루기%20위한%20리커런트%20뉴럴넷_assets/2023-03-08-13-38-54-image.png" title="" alt="" width="162">
            
            1. filter가 눈이 있을 것 같은 위치에서 값이 높게 나와 activation을 만든다
            
            2. activation을 모아서 값을 종합하여 눈이 있는지 없는지 여부를 확인하여 정확도를 높일 수 있다
               
               <img src="3.순차적%20데이터를%20다루기%20위한%20리커런트%20뉴럴넷_assets/2023-03-08-13-41-30-image.png" title="" alt="" width="314">
               
               - max pooling
                 
                 - filter 안에 들어온 값 중 가장 가장 큰 값을 가져와서 결과를 만듬 
               
               - average pooling
                 
                 - filter 안에 들어온 값의 평균 값을 결과를 만듬
          
          - pooling layer의 사용이유
            
            - convolution layer의 filter size의 제한의 단점을 이겨내고, 쉽고 많은 범위를 보기위해 사용
      
      ---
      
      - Activation function
        
        - 종류
          
          <img title="" src="3.순차적%20데이터를%20다루기%20위한%20리커런트%20뉴럴넷_assets/2023-03-08-14-04-21-image.png" alt="" width="546">
          
          1. identity : layer가 깊어져도 하나의 layer의 뉴럴 네트워크로 치환
             
             - 선형네트워크만 표현 가능
             
             - layer를 깊게 쌓아도 의미가 없음
          
          2. non linear를 추가하면 convolution layer를 쌓을 때마다 복잡한 함수로 사용 가능
             
             - 최근 가장 많이 사용 되는 함수 : ReLU
  
  ---
  
  - Fully Connected layer (FC layer)
    
    <img title="" src="3.순차적%20데이터를%20다루기%20위한%20리커런트%20뉴럴넷_assets/2023-03-08-14-07-43-image.png" alt="" width="558">
    
    - convolution / pooling / RELU와 같은 non linear function을 쌓아 actication layer를 생성
    
    - actication layer를 백터로 변환 후 최종적으로 Fully Connected layer로 하나의 값으로 만들어준다
    
    ---
    
    - 뉴럴네트워크의 한 layer를 정할 때 가장 기본적인 layer
    
    - 32X32X3 이미지를 백터 형태로 변형하여 3072X1로 늘림
      
      ![](3.순차적%20데이터를%20다루기%20위한%20리커런트%20뉴럴넷_assets/2023-03-08-14-18-13-image.png)
      
      - W를 정할 때 input의 채널사이즈인 3072와 출력의 채널사이즈인 10으로 10 X 3072로 만든다
      
      <img src="3.순차적%20데이터를%20다루기%20위한%20리커런트%20뉴럴넷_assets/2023-03-08-14-20-22-image.png" title="" alt="" width="225">
      
      - 3072는 이미지의 모든 부분에 대해 대응되기 때문에 모든 input에 대해 고려한 결과 == Fully connected

---

- CNN은 어떤 지식을 학습하는가?
  
  - 계층적 특징 표현
    
    - Convolution layer의 적층을 통해 자연스럽게 유도된 특징
      
      <img title="" src="3.순차적%20데이터를%20다루기%20위한%20리커런트%20뉴럴넷_assets/2023-03-08-14-26-43-image.png" alt="" width="218">

---

- AlexNet
  
  ![](3.순차적%20데이터를%20다루기%20위한%20리커런트%20뉴럴넷_assets/2023-03-08-14-30-08-image.png)
  
  - convolution / pooling / LRN(정규화하는 layer)를 쌓아 구조를 만듬
  
  - FC layer에서 나는 하나의 벡터는 1000차원(dimension)

- AlexNet(original)
  
  <img src="3.순차적%20데이터를%20다루기%20위한%20리커런트%20뉴럴넷_assets/2023-03-08-14-33-31-image.png" title="" alt="" width="400">
  
  <img src="3.순차적%20데이터를%20다루기%20위한%20리커런트%20뉴럴넷_assets/2023-03-08-14-34-32-image.png" title="" alt="" width="403">
  
  - LRN 보다 Batch로 정규화 하는 것이 훨씬 성능이 좋아 현재는 Batch 사용

---

- VGGNet
  
  - 16 ~ 19 layer의 더 깊은 아키텍처 (Alexnet은 11개)
  
  - 간결한 아키텍쳐
    
    - LRN 없애고
    
    - convolution filter 3X3 만 사용
    
    - max pooling 2X2 만 사용
  
  - 더 좋은 퍼포먼스
    
    - alexnet보다 획기적으로 좋은 성능
  
  - 더 좋은 일반화 성능
    
    - Fine tuning 없이 다른 방법으로 일반화

---

- Degradation problem
  
  - 네트워크 깊이에 따라 정확도가 빠르게 수렴하지만 성능이 나빠짐
  
  - over fitting의 문제가 아니라 최적화의 문제
    
    <img src="3.순차적%20데이터를%20다루기%20위한%20리커런트%20뉴럴넷_assets/2023-03-08-14-38-42-image.png" title="" alt="" width="479">

- ResNet
  
  - Degradation problem을 해결하기 위해 등장
    
    <img src="3.순차적%20데이터를%20다루기%20위한%20리커런트%20뉴럴넷_assets/2023-03-08-14-40-57-image.png" title="" alt="" width="496">
  
  - gradient가 함수를 통해 지나갈 수 있지만 우회하는 값도 고려하여 최적화가 훨씬 잘되게 만들었다
